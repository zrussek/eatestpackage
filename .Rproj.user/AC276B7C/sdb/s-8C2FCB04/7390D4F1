{
    "collab_server" : "",
    "contents" : "---\ntitle: \"QC on Assessment data\"\nauthor: \"Education Analytics\"\ndate: \"`r format(Sys.time(), '%d %B, %Y')`\"\noutput:\n  html_document:\n    theme: journal\n    css: system.file(\"rmd/table_of_contents.css\", package=\"eatestpackage\")\n    toc: yes\nparams:\n  file_name: x\n  opt_graphs: x\n  outlier_parm: x\n  missing_parm: x\n  duplicate_parm: x\n  \n---   \n\n---\n\n\n```{r, echo=FALSE, include=FALSE}\n\n######################################################################################\n# all qc code goes in this first chunck, all html output will be in the chunks below #\n######################################################################################\n\n# load packages \nlibrary(data.table)\nlibrary(DT)\nlibrary(easimple)\nlibrary(gridExtra)\nlibrary(ggplot2)\n\n# create copy of test data\nin_test <- copy(params$file_name)\n\n###################\n# save parameters #\n###################\n\n  # interval parameter\n  outlier_parm <- params$outlier_parm\n  \n  # duplicate parameter\n  dup_parm <- params$duplicate_parm\n\n  # threshold for % of missing...\n  missing_parm <- params$missing_parm\n  \n  # set colors\n  c_good    <- \"white\"\n  c_warning <- \"#FFEB9C\"\n  c_problem <- \"#FFC7CE\"\n\n#########################\n# 0. GENERAL FORMATTING #\n#########################\n  \n  # make test_scale_score and test_sem numeric\n  in_test[, test_scale_score := as.numeric(test_scale_score)]\n  in_test[, test_sem := as.numeric(test_sem)]\n  \n  # convert NA grades to 99\n  in_test[is.na(test_grade), test_grade:=99]\n  \n  # make test grade two characters\n  in_test[nchar(as.character(test_grade)) == 1 & !grepl(\"k\", test_grade), test_grade := paste0(0, test_grade)]\n\n  ################\n  # create lists #\n  ################\n  \n  # list of years\n  year_list <- unique(in_test$test_school_year)\n  \n  # list of grades\n  grade_list <- unique(in_test$test_grade)\n  \n  # sort grade list low to high\n  grade_list <- sort(grade_list, decreasing=FALSE)\n  \n  # put k and pk on front end of list if they exists\n  if ( (\"k\" %chin% grade_list) & (\"pk\" %chin% grade_list)) { \n    other_grades <- setdiff(grade_list, c(\"k\", \"pk\"))\n    other_grades <- sort(other_grades, decreasing=FALSE)\n    grade_list   <- c(\"pk\", \"k\", other_grades)}\n  \n  # put k on front end of list if they exists\n  if ( (\"k\" %chin% grade_list) & !(\"pk\" %chin% grade_list)) { \n    other_grades <- setdiff(grade_list, c(\"k\"))\n    other_grades <- sort(other_grades, decreasing=FALSE)\n    grade_list   <- c(\"k\", other_grades)}\n  \n  # put pk on front end of list if they exists\n  if ( !(\"k\" %chin% grade_list) & (\"pk\" %chin% grade_list)) { \n    other_grades <- setdiff(grade_list, c(\"pk\"))\n    other_grades <- sort(other_grades, decreasing=FALSE)\n    grade_list   <- c(\"pk\", other_grades)}\n\n  \n##########################\n# TABLE 1: GENERAL TABLE #\n##########################\n  \n  # .i. create general table \n  general_table <- in_test[, list(total_n_obs       = .N,\n                                  n_unique_tests    = length(unique(ea_test_name)),\n                                  n_unique_students = length(unique(ea_student_id))),\n                           by=\"test_school_year\"]\n  \n  # .ii. output n_exact duplicate rows\n  exact_dups <- ea_out_dups(in_test, opt_key_all = 1)\n  \n  # .ii. calcualte number of exact rows per year\n  exact_dups_table <- exact_dups[, list(exact_dup_row=.N), by=\"test_school_year\"]\n  \n  # .ii. merge duplicate row info onto general table\n  general_table <- ea_merge(general_table, exact_dups_table, \"test_school_year\", \"x\")\n  \n  # .ii. create a % of duplicate rows\n  general_table[, perc_exact_dup_row := round((exact_dup_row/total_n_obs)*100, 2)]\n  \n   # .iii. make all NA values = 0\n  general_table[is.na(general_table)] <- 0\n  \n  # .iv. sort years from high to low\n  general_table <- general_table[order(-(test_school_year))]\n  \n  # .v. convert to datatable\n  general_table_dt <- datatable(general_table, rownames = FALSE, extensions = \"KeyTable\")\n\n  #######################################\n  # flag large disparities across years #\n  #######################################\n\n  ################################################\n  # check 1.1 -> outliers of total_n_obs by year #\n  ################################################\n\n  # set intervals\n  lower_int <- (mean(general_table$total_n_obs) - (mean(general_table$total_n_obs))*(outlier_parm))\n  upper_int <- (mean(general_table$total_n_obs) + (mean(general_table$total_n_obs))*(outlier_parm))\n\n  # apply color scheme\n  general_table_dt <- formatStyle(general_table_dt, columns = \"total_n_obs\", background = styleInterval(c(lower_int, upper_int), c(c_problem, c_good, c_problem)))\n  \n  # internal flag for general table\n  if ( (min(general_table$total_n_obs) < lower_int) | (max(general_table$total_n_obs) > upper_int)) {\n    general_table_flag <- 1\n  } else { \n    general_table_flag <- 0}\n  \n  ###################################################\n  # check 1.2 -> outliers of n_unique_tests by year #\n  ###################################################\n  \n  # set intervals\n  lower_int <- (mean(general_table$n_unique_tests) - (mean(general_table$n_unique_tests))*(outlier_parm))\n  upper_int <- (mean(general_table$n_unique_tests) + (mean(general_table$n_unique_tests))*(outlier_parm))\n  \n  # apply color scheme\n  general_table_dt <- formatStyle(general_table_dt, columns = \"n_unique_tests\", background = styleInterval(c(lower_int, upper_int), c(c_problem, c_good, c_problem)))\n  \n  # internal flag for general table\n  if ( (min(general_table$n_unique_tests) < lower_int) | (max(general_table$n_unique_tests) > upper_int)) {general_table_flag <- 1}\n   \n  ######################################################\n  # check 1.3 -> outliers of n_unique_students by year #\n  ######################################################\n  \n  # set intervals\n  lower_int <- (mean(general_table$n_unique_students) - (mean(general_table$n_unique_students))*(outlier_parm))\n  upper_int <- (mean(general_table$n_unique_students) + (mean(general_table$n_unique_students))*(outlier_parm))\n  \n  # apply color scheme\n  general_table_dt <- formatStyle(general_table_dt, columns = \"n_unique_students\", background = styleInterval(c(lower_int, upper_int), c(c_problem, c_good, c_problem)))\n  \n  # internal flag for general table\n  if ( (min(general_table$n_unique_students) < lower_int) | (max(general_table$n_unique_students) > upper_int)) {general_table_flag <- 1}\n  \n  #########################################################################\n  # check 1.4 -> % of duplicate rows is higher than the missing threshold #\n  #########################################################################\n  \n  # apply color scheme to % exact duplicate row\n  general_table_dt <- formatStyle(general_table_dt, columns = \"perc_exact_dup_row\", background = styleInterval(c(0, dup_parm), c(c_good, c_warning, c_problem)))\n  \n  # internal flag for general table\n  if (sum(general_table$perc_exact_dup_row, na.rm = TRUE)!=0) {\n    \n    if ( (min(general_table$perc_exact_dup_row, na.rm = TRUE) > dup_parm)) {general_table_flag <- 1}\n  \n    }\n    \n\n\n####################################\n# TABLE 2: MISSING VARIABLES TABLE #\n####################################\n\n  # create a copy of in_test as a data.frame\n  missing_vars <- as.data.frame(copy(in_test))\n  \n  # subset test dataset to missing vars\n  missing_vars <-  missing_vars[sapply(missing_vars, function(x) all(is.na(x)))]\n  \n  # create list of all missing vars\n  miss_var_list <- colnames(missing_vars)\n  \n  # create data.table of remaining columns\n  miss_var_table <- as.data.table(colnames(in_test))\n  \n  # setnames\n  setnames(miss_var_table, \"V1\", \"variable\")\n  \n  # create a missing flag\n  miss_var_table[, missing := ifelse(variable %chin% miss_var_list, 1,0)]\n  \n  # datatable \n  miss_var_dt <- datatable(miss_var_table, rownames = FALSE, extensions = \"Scroller\", options=list(deferRender=TRUE, scrollY=400, scrollCollapse=TRUE))\n\n  # apply color scheme: highlight missing vars\n  miss_var_dt <- formatStyle(miss_var_dt, columns = \"missing\", background = styleEqual(c(0, 1), c(c_good, c_problem)))\n\n  # check 2.1 -> internal flag for list of missing vars\n  if (length(miss_var_list)>0) {\n    missing_vars_flag <- 1\n  } else { missing_vars_flag <- 0}\n  \n  \n#################################\n# TABLE 3: MISSING DATA % TABLE #\n#################################\n  \n  # create table\n  missing_table <- in_test[, list(total_n_obs         = .N,\n                                  missing_student_id  = sum(is.na(ea_student_id)),\n                                  missing_scale_score = sum(is.na(test_scale_score)),\n                                  missing_test_sem    = sum(is.na(test_sem)),\n                                  missing_test_date   = sum(is.na(test_date)),\n                                  missing_test_term   = sum(is.na(test_term))),\n                           by=\"test_school_year\"]\n  \n  # add %'s to table\n  missing_table[, perc_miss_stud_id     := round((missing_student_id/total_n_obs)*100, 2)]\n  missing_table[, perc_miss_scale_score := round((missing_scale_score/total_n_obs)*100, 2)]\n  missing_table[, perc_miss_test_sem    := round((missing_test_sem/total_n_obs)*100, 2)]\n  missing_table[, perc_miss_test_date   := round((missing_test_date/total_n_obs)*100, 2)]\n  missing_table[, perc_miss_test_term   := round((missing_test_term/total_n_obs)*100, 2)]\n  \n  # sort column order\n  ea_colorder(missing_table, c(\"test_school_year\", \"total_n_obs\", \"missing_student_id\", \"perc_miss_stud_id\", \"missing_scale_score\", \"perc_miss_scale_score\",\n                               \"missing_test_sem\", \"perc_miss_test_sem\", \"missing_test_date\", \"perc_miss_test_date\", \"missing_test_term\", \"perc_miss_test_term\"))\n  \n  # sort years from high to low\n  missing_table <- missing_table[order(-(test_school_year))]\n\n  # the following code pre-hides the \"extra\" columns and allows you to open more if you want more info\n  missing_dt <- datatable(missing_table, rownames=FALSE, extensions = 'ColVis', options = list(columnDefs = list(list(targets = c(1,2,4,6,8,10), visible = FALSE)),\n                                                                                        dom = 'C<\"clear\">lfrtip'))\n\n\n  ##################################\n  # flag large %'s of missing data #\n  ##################################\n\n  # .i. check 3.1 -> 3.5 apply color scheme to all percent missings from \"missing_table\"\n  missing_dt <- formatStyle(missing_dt, columns = c(\"perc_miss_stud_id\", \"perc_miss_scale_score\", \"perc_miss_test_sem\", \"perc_miss_test_date\", \"perc_miss_test_term\"),\n                            background = styleInterval(c(0, missing_parm), c(c_good, c_warning, c_problem)))\n  \n  # internal flag for missing table\n  if ( (max(missing_table$perc_miss_stud_id) > missing_parm) | (max(missing_table$perc_miss_scale_score) > missing_parm) |  \n       (max(missing_table$perc_miss_test_sem) > missing_parm) | (max(missing_table$perc_miss_test_date) > missing_parm) |  \n       (max(missing_table$perc_miss_test_term) > missing_parm)) {\n  \n      missing_table_flag <- 1\n    } else {\n      missing_table_flag <- 0}\n    \n\n################################\n# TABLE 4: ID ISSUES (BY TEST) #\n################################\n  \n  ####################################\n  # find total_n_obs per unique test #\n  ####################################\n  \n  # create table of total count per unique test\n  students_per_test <-  ea_table(in_test, c(\"ea_test_name\", \"site_test_abbrev\", \"ea_test_subject\", \"test_grade\", \"test_term\", \"test_school_year\"))\n  \n  # count -> total_n_obs\n  setnames(students_per_test, \"count\", \"total_n_obs\")\n  \n  ##########################################\n  # find n_unique_students per unique test #\n  ##########################################\n  \n  # find n_unique_students\n  sub_test <- ea_no_dups(in_test, c(\"ea_student_id\", \"ea_test_name\",\"site_test_abbrev\", \"ea_test_subject\", \"test_grade\", \"test_term\", \"test_school_year\"))\n  \n  # make table\n  unique_studs <-  ea_table(sub_test, c(\"ea_test_name\",\"site_test_abbrev\", \"ea_test_subject\", \"test_grade\", \"test_term\", \"test_school_year\"))\n  \n  # setnames\n  setnames(unique_studs, \"count\", \"n_unique_students\")\n  \n  # merge onto original table\n  students_per_test <- ea_merge(students_per_test, unique_studs, c(\"ea_test_name\",\"site_test_abbrev\", \"ea_test_subject\", \"test_grade\", \"test_term\", \"test_school_year\"), \"x\")\n  \n  #######################################################\n  # find n_duplicate_students (overall) per unique test #\n  #######################################################\n  \n  # find number of duplicate students per test\n  dup_studs <- ea_out_dups(in_test, c(\"ea_student_id\", \"ea_test_name\",\"site_test_abbrev\", \"ea_test_subject\", \"test_grade\", \"test_term\", \"test_school_year\"))\n  \n  # count dups\n  dup_studs_table <- dup_studs[, list(n_dup_studs=.N), by=c(\"ea_test_name\",\"site_test_abbrev\", \"ea_test_subject\", \"test_grade\", \"test_term\", \"test_school_year\")]\n  \n  # merge onto original table\n  students_per_test <- ea_merge(students_per_test, dup_studs_table, c(\"ea_test_name\",\"site_test_abbrev\", \"ea_test_subject\", \"test_grade\", \"test_term\", \"test_school_year\"), \"x\")\n  \n  # convert NA values to zeroes\n  students_per_test[is.na(n_dup_studs), n_dup_studs:=0]\n  \n  ############################################################\n  # find n_duplicate_students that have the same scale score #\n  ############################################################\n  \n  # find number of duplicate students with the same scale scores\n  dup_studs_same_ss <- ea_out_dups(dup_studs, c(\"ea_student_id\", \"ea_test_name\",\"site_test_abbrev\", \"ea_test_subject\", \"test_grade\", \n                                                \"test_term\", \"test_school_year\", \"test_scale_score\"))\n  \n  # count dups\n  same_ss_table <- dup_studs_same_ss[, list(n_dup_studs_same_ss=.N), by=c(\"ea_test_name\",\"site_test_abbrev\", \"ea_test_subject\", \"test_grade\", \"test_term\", \"test_school_year\")]\n  \n  # merge onto original table\n  students_per_test <- ea_merge(students_per_test, same_ss_table, c(\"ea_test_name\",\"site_test_abbrev\", \"ea_test_subject\", \"test_grade\", \"test_term\", \"test_school_year\"), \"x\")\n  \n  # convert NA values to zeroes\n  students_per_test[is.na(n_dup_studs_same_ss), n_dup_studs_same_ss:=0]\n  \n  ##############################################################\n  # find n_duplicate_students that have different scale scores #\n  ##############################################################\n  \n  # subset dup studs to just test, student and score\n  dup_studs <- subset(dup_studs, select = c(\"ea_test_name\",\"site_test_abbrev\", \"ea_test_subject\", \"test_grade\", \"test_term\", \"test_school_year\",\"ea_student_id\", \"test_scale_score\"))\n  \n  # create column with # of times the scale score appears\n  diff_ss <- dup_studs[,list(n_scale_score=.N),by=c(\"ea_test_name\" ,\"ea_student_id\", \"test_scale_score\")]\n  \n  # count the number of times a certain test appears {{with more than one score}}\n  diff_ss <- diff_ss[,list(n_dup_studs_diff_ss=.N),by=c(\"ea_test_name\")]\n  \n  # merge the # of duplicate studs with non-matching scale scores onto table\n  students_per_test <- ea_merge(students_per_test, diff_ss, \"ea_test_name\", \"x\")\n  \n  # convert NA values to zeroes\n  students_per_test[is.na(n_dup_studs_diff_ss), n_dup_studs_diff_ss:=0]\n  \n  ##############\n  # create %'s #\n  ##############\n  \n  # % of unique ids\n  students_per_test[, perc_unique_studs := round((n_unique_students/total_n_obs)*100, 2)]\n  \n  # % of dup ids\n  students_per_test[, perc_dup_studs := round((n_dup_studs/total_n_obs)*100, 2)]\n\n  # % of dup ids diff ss\n  students_per_test[, perc_dup_studs_diff_ss := round((n_dup_studs_diff_ss/total_n_obs)*100, 2)]\n  \n  ##########\n  # format #\n  ##########\n  \n   # the following code pre-hides the \"extra\" columns and allows you to open more if you want more info\n   students_per_test_dt <- datatable(students_per_test, rownames=FALSE, extensions = c('ColVis', 'FixedHeader'), \n                                      options = list(columnDefs = list(list(targets = c(1,2,3,4,5,6,7,8,9,10), visible = FALSE)), dom = 'C<\"clear\">lfrtip'))\n\n  #########################################\n  # flag large # of duplicate student ids #\n  #########################################\n    \n  # .i. flag 4.1 -> perc_unique_studs less than 99%\n  students_per_test_dt <- formatStyle(students_per_test_dt, columns = c(\"perc_unique_studs\"), background = styleInterval(c(95,99), c(c_problem, c_warning, c_good)))\n  \n  # .ii. flags 4.2 - 4.3 -> perc_dup_studs greater than 5% and perc_dup_studs_diff_ss greater than 5%\n  students_per_test_dt <- formatStyle(students_per_test_dt, columns = c(\"perc_dup_studs\", \"perc_dup_studs_diff_ss\"), \n                                      background = styleInterval(c(1, dup_parm), c(c_good, c_warning, c_problem)))\n   \n  # .i. internal flag for 4.1\n  if ( (min(students_per_test$perc_unique_studs) < 99 )) {\n    \n    students_per_test_flag <- 1\n  } else {\n    students_per_test_flag <- 0}\n  \n  # .ii. internal flag for 4.2 - 4.3\n  if ( (max(students_per_test$perc_dup_studs) > dup_parm) | (max(students_per_test$perc_dup_studs_diff_ss) > dup_parm)) {students_per_test_flag <- 1}\n  \n\n#########################################\n# TABLE 5: STUDENTS PER GRADE (BY TEST) #\n#########################################\n\n  # remove duplicate students\n  sub_test <- ea_no_dups(in_test, c(\"ea_student_id\", \"ea_test_name\"))\n  \n  # create table with grade\n  students_per_grade <-  ea_table(sub_test, c(\"site_test_abbrev\", \"ea_test_subject\", \"test_grade\", \"test_school_year\", \"test_term\"))\n  \n  # put wide\n  students_per_grade <- data.table(dcast(students_per_grade, site_test_abbrev + ea_test_subject + test_school_year + test_term ~ test_grade, value.var = \"count\"))\n  \n  # create table without grade (count=# of students in that model, not accounting for grade) \n  sum_grades <-  ea_table(sub_test, c(\"site_test_abbrev\", \"ea_test_subject\", \"test_school_year\", \"test_term\"))\n  \n  # setnames\n  setnames(sum_grades, \"count\", \"n_total\")\n  \n  # merge together\n  students_per_grade <- ea_merge(students_per_grade, sum_grades, c(\"site_test_abbrev\", \"ea_test_subject\", \"test_school_year\", \"test_term\"))\n  \n   # make column name grade \"missing\" if it exists\n  if (\"99\" %chin% grade_list) {setnames(students_per_grade, \"99\", \"missing\")}\n  \n  # create new grade_list\n  grade_list_t5 <- copy(grade_list)\n  \n  # replace \"99\" with \"missing\" for new grade list\n  if (\"99\" %chin% grade_list_t5) {grade_list_t5 <- gsub(\"99\", \"missing\", grade_list)}\n\n  ##############################################\n  # create column with number of missing years #\n  ##############################################\n  \n  # set n_no_students to zero\n  students_per_grade[, n_no_students:=0]\n  \n  # loop over years and create zero_\"grade\" columns\n  for (grade in grade_list_t5) {\n    \n    # create column that indicates if this grade has zero students\n    students_per_grade[, zero_students:=ifelse(get(grade)==0, 1, 0)]\n    \n    # add zero_students onto n_no_students\n    students_per_grade[, n_no_students:= n_no_students + zero_students]}\n  \n  # drop zero students flag\n  students_per_grade[, zero_students:=NULL]\n\n  \n  ############################################\n  # create max/min/mean for each grade level #\n  ############################################\n\n  # set max/min/flag_missing_grade to zero\n  students_per_grade[, flag_missing_grade:=0]\n  students_per_grade[, max:=0]\n  students_per_grade[, min:=0]\n  \n  # save \"first_grade\" in list\n  first_grade <- grade_list_t5[1]\n  \n  # loop over grade_list\n  for (grade in grade_list_t5) {\n    \n    # flag missing grade of data if grade==0\n    students_per_grade[flag_missing_grade==0, flag_missing_grade:=ifelse(get(grade)==0, 1, 0)]\n    \n    # set first grade to be equal to the max and the min\n    if(grade==first_grade) {students_per_grade[,max:=get(grade)]\n                            students_per_grade[,min:=get(grade)]}\n    \n    # for all other grades...\n    if(grade!=first_grade) {\n      \n      # create a comparison size column\n      students_per_grade[, comp_size:=get(grade)]\n      \n      # if comp_size is bigger than the current max, overwrite\n      students_per_grade[comp_size > max, max:=get(grade)]\n      \n      # if comp_size is smaller than the current min, overwrite { OR if min is still zero, reset the minimum to this new value}\n      students_per_grade[( ((comp_size < min) & comp_size!=0) | min==0), min:=get(grade)]\n      \n    }\n  }\n  \n  # save the number of grades\n  n_grades <- length(grade_list_t5)\n  \n  # if a missing grade exists, subtract it\n  if(\"missing\" %chin% grade_list_t5) {n_grades <- n_grades -1 }\n  \n  # create mean\n  students_per_grade[,mean_with_students:= (n_total / (n_grades-n_no_students))]\n  \n  #######################\n  # implement flag rule #\n  #######################\n  \n  # set flag to zero\n  students_per_grade[ , large_disparity:=0]\n  \n  # brule\n  students_per_grade[ (max >= (mean_with_students + outlier_parm*(mean_with_students))) | \n                        (min <= (mean_with_students - outlier_parm*(mean_with_students))), large_disparity:=1]\n  \n  ################\n  # format table #\n  ################\n  \n  # get rid of comp_size/mean\n  students_per_grade[, comp_size:=NULL]\n  students_per_grade[, mean_with_students:=NULL]\n  students_per_grade[, n_no_students:=NULL]\n\n  # column order\n  ea_colorder(students_per_grade, c(\"site_test_abbrev\", \"ea_test_subject\", \"test_school_year\", \"test_term\", grade_list_t5, \"large_disparity\", \"flag_missing_grade\", \"n_total\"))\n  \n  ############################################\n  # convert to datatable and highlight flags #\n  ############################################\n  \n  # the following code hides n_total, max, min\n  students_per_grade_dt <- datatable(students_per_grade, rownames=FALSE, extensions = c('ColVis', 'FixedHeader'), \n                                     options = list(columnDefs = list(list(targets = c(-1,-2,-3), visible = FALSE)), dom = 'C<\"clear\">lfrtip'))\n  \n  # check 5.1 -> highlight cells where large_disparity flag is 1\n  students_per_grade_dt <- formatStyle(students_per_grade_dt, columns = c(\"large_disparity\", \"flag_missing_grade\"), background = styleEqual(c(0, 1), c(c_good, c_problem)))\n  \n  # internal flag 5.1\n  if ( sum(students_per_grade$large_disparity)>0) {\n    \n    students_per_grade_flag <- 1\n  } else { \n    students_per_grade_flag <- 0}\n  \n  # internal flag 5.2\n  if (sum(students_per_grade$flag_missing_grade, na.rm = TRUE)!=0) {\n    \n    if(sum(students_per_grade$flag_missing_grade, na.rm = TRUE)>0) {students_per_grade_flag <- 1}\n    \n  }\n  \n\n#########################################\n# TABLE 6: STUDENTS PER YEAR (BY TEST) #\n#########################################\n  \n  # remove duplicate students\n  sub_test <- ea_no_dups(in_test, c(\"ea_student_id\", \"ea_test_name\"))\n  \n  # create table with grade\n  within_grade_comp <-  sub_test[, list(site_test_abbrev=site_test_abbrev, ea_test_subject=ea_test_subject, test_grade=test_grade, test_term=test_term),by=\"test_school_year\"]\n  \n  # put wide\n  within_grade_comp <- data.table(dcast(within_grade_comp, site_test_abbrev + ea_test_subject + test_grade + test_term ~ test_school_year))\n  \n  # calculate n_total\n  within_grade_total <- ea_table(sub_test, c(\"site_test_abbrev\", \"ea_test_subject\", \"test_grade\", \"test_term\"))\n  \n  # merge on total\n  within_grade_comp <- ea_merge(within_grade_comp, within_grade_total, c(\"site_test_abbrev\", \"ea_test_subject\", \"test_grade\", \"test_term\"))\n  \n  # setkey\n  setkey(within_grade_comp, site_test_abbrev, ea_test_subject, test_grade, test_term)\n  \n  ##############################################\n  # create column with number of missing years #\n  ##############################################\n  \n  # set n_no_students to zero\n  within_grade_comp[, n_no_students:=0]\n  \n  # loop over years and create zero_\"year\" columns\n  for (year in year_list) {\n  \n    # create column that indicates if this year has zero students\n    within_grade_comp[, zero_students:=ifelse(get(year)==0, 1, 0)]\n  \n    # add zero_students onto n_no_students\n    within_grade_comp[, n_no_students:= n_no_students + zero_students]}\n  \n  # drop zero students flag\n  within_grade_comp[, zero_students:=NULL]\n  \n  ############################################\n  # create max/min/mean for each grade level #\n  ############################################\n  \n  # set max/min/flag_missing_year to zero\n  within_grade_comp[, flag_missing_year:=0]\n  within_grade_comp[, max:=0]\n  within_grade_comp[, min:=0]\n  \n  # save \"first_year\" in list\n  first_year <- year_list[1]\n  \n  # loop over grade_list\n  for (year in year_list) {\n    \n    # flag missing year of data if year==0\n    within_grade_comp[flag_missing_year==0, flag_missing_year:=ifelse(get(year)==0, 1, 0)]\n  \n    # set first year to be equal to the max and the min \n    if(year==first_year) {within_grade_comp[,max:=get(year)]\n                          within_grade_comp[,min:=get(year)]}\n    \n    # for all other grades...\n    if(year!=first_year) {\n  \n      # create a comparison size column\n      within_grade_comp[, comp_size:=get(year)]\n  \n      # if comp_size is bigger than the current max, overwrite\n      within_grade_comp[comp_size > max, max:=get(year)]\n  \n      # if comp_size is smaller than the current min, overwrite { OR if min is still zero, reset the minimum to this new value}\n      within_grade_comp[( ((comp_size < min) & comp_size!=0) | min==0), min:=get(year)]\n  \n    }\n  }\n  \n  # save the number of years\n  n_years <- length(year_list)\n  \n  # create mean\n  within_grade_comp[,mean_with_students:= (count / (n_years-n_no_students))]\n\n  #######################\n  # implement flag rule #\n  #######################\n  \n  # set flag to zero\n  within_grade_comp[ , large_disparity:=0]\n  \n  # brule\n  within_grade_comp[ (max >= (mean_with_students + outlier_parm*(mean_with_students))) | (min <= (mean_with_students - outlier_parm*(mean_with_students))), large_disparity:=1]\n\n\n  ################\n  # format table #\n  ################\n  \n  # get rid of vars\n  within_grade_comp[, comp_size:=NULL]\n  within_grade_comp[, mean_with_students:=NULL]\n  within_grade_comp[, n_no_students:=NULL]\n  within_grade_comp[, count:=NULL]\n  \n  # column order\n  ea_colorder(within_grade_comp, c(\"site_test_abbrev\", \"ea_test_subject\", \"test_grade\", \"test_term\", year_list, \"large_disparity\", \"flag_missing_year\"))\n  \n\n  ############################################\n  # convert to datatable and highlight flags #\n  ############################################\n  \n  # the following code hides n_total, max, min\n  within_grade_dt <- datatable(within_grade_comp, rownames=FALSE, extensions = c('ColVis', 'FixedHeader'), \n                               options = list(columnDefs = list(list(targets = c(-1,-2), visible = FALSE)),dom = 'C<\"clear\">lfrtip'))\n  \n  # check 6.1 -> highlight cells where large_disparity flag is 1\n  within_grade_dt <- formatStyle(within_grade_dt, columns = c(\"large_disparity\", \"flag_missing_year\"), background = styleEqual(c(0, 1), c(c_good, c_problem)))\n  \n  # internal flag 6.1\n  if ( sum(within_grade_dt$large_disparity)>0) {\n  \n    within_grade_flag <- 1\n  } else {\n    within_grade_flag <- 0}\n  \n  # internal flag 6.2\n  if(sum(within_grade_comp$flag_missing_year)>0) {within_grade_flag <- 1}\n\n\n  \n#######################################\n# TABLE 7: SCALE SCORE INFO (BY TEST) #\n#######################################\n\n    # add flag for missing ss\n    in_test[, flag_ss_missing:= ifelse(is.na(test_scale_score), 1, 0)]\n\n    # find min, max, mean, sd by unique test\n    ss_model_stats <- in_test[, list(n_obs   = .N,\n                                     ss_min  = min(test_scale_score, na.rm = TRUE),\n                                     ss_max  = max(test_scale_score, na.rm = TRUE),\n                                     ss_mean = round(mean(test_scale_score, na.rm = TRUE)),\n                                     ss_sd   = round(sd(test_scale_score, na.rm = TRUE)),\n                                     n_missing_ss = sum(flag_ss_missing),\n                                     perc_missing_ss = round(mean(flag_ss_missing)*100,2)),\n                                     by = c(\"ea_test_name\", \"site_test_abbrev\", \"ea_test_subject\", \"test_grade\", \"test_school_year\", \"test_term\")]\n    \n    # set column order\n    setkey(ss_model_stats, ea_test_subject, test_grade, test_school_year, test_term)\n\n    # sort years from high to low\n    ss_model_stats <- ss_model_stats[order(-(test_school_year))]\n    \n    # convert to DT\n    ss_model_stats_dt <- datatable(ss_model_stats, rownames=FALSE, extensions = c('ColVis', 'FixedHeader'), \n                                   options = list(columnDefs = list(list(targets = c(1,2,3,4,5,6,11), visible = FALSE)),dom = 'C<\"clear\">lfrtip'))\n\n    #################\n    # flag problems #\n    #################\n\n    # .i. flag 7.1 -> perc_missing_ss more than 2.5%\n    ss_model_stats_dt <- formatStyle(ss_model_stats_dt, columns = c(\"perc_missing_ss\"), background = styleInterval(c(.001,missing_parm), c(c_good, c_warning, c_problem)))\n    \n    # .i. internal flag for 7.1\n    if ( (max(ss_model_stats_dt$perc_missing_ss) > 2.5 )) {\n      \n      ss_model_stats_flag <- 1\n    } else {\n      ss_model_stats_flag <- 0}\n    \n     \n    \n#########################\n# HISTOGRAMS SS and SEM #\n#########################\n  \n  # create empty list\n  test_hist_list <- list()\n  \n  # create list of unique tests\n  model_list <- unique(in_test$ea_test_name)\n  \n  # loop over models to histogram and sum stat\n  for (m in 1 : length(model_list)){\n    \n    # define model\n    m_model_list <- model_list[m]\n    \n    # subset in_test\n    m_test <- subset(in_test, ea_test_name == m_model_list, select = c(\"ea_student_id\", \"test_scale_score\", \"test_sem\"))\n    \n    # put long\n    m_test_long <- melt(m_test, \"ea_student_id\", c(\"test_scale_score\", \"test_sem\"))\n    \n    # histogram\n    h <- ggplot(m_test_long, aes(value)) + geom_histogram() + facet_wrap(~ variable, ncol = 1, scale=\"free\")\n    h <- h + ggtitle(paste0(\"scale score and sem  \", m_model_list))\n    \n    # save to list\n    test_hist_list[[m_model_list]] <- h\n    \n  }\n\n\n##################\n# to be added....#\n##################\n  \n# across grades/years/terms Cohort info for students, flag potential issues  \n  \n# Missing data \n  # need to differentiate between mandatory variables and optional vars\n\n# ID issues\n  # notify when more than one student ID exists in raw data, which to use\n  # if both state/local ids exist, analyze their uniqueness & overlap\n  # Check for bad id's\n    # non alpha-numeric numbers\n    # leading zeroes\n    # scientific notation\n\n# By school info\n  # grade spans per school & year\n    # check for missing grades, weird spans, large changes\n  \n  # number of students per school & year\n    # by school\n    # by school and grade\n    # flag any large changes in n-sizes at a school across years\n  \n\n  # an overall flag for whether or nor the headings \"flagged/unflagged should appear aka...is anything flagged?\" -->\n\n\n\n```\n\n<br>\n\n\n## Flagged Checks\n*Below are all the the quality control checks that have been flagged for possible problems*\n\n<br>\n\n\n`r if (general_table_flag==1) '### general table' `\n```{r, echo = FALSE,  fig.align='center', fig.width=10, comment=NULL}\n\n##########################\n# table 1: general table #\n##########################\n\nif (general_table_flag==1){  general_table_dt}\n\n```\n\n<br>\n\n`r if (missing_vars_flag==1) '### missing variables' `\n```{r, echo = FALSE,  fig.align='center', fig.width=10, comment=NULL}\n\n##############################\n# table 2: missing variables #\n##############################\n\nif (missing_vars_flag==1) {miss_var_dt}\n\n```\n\n<br>\n\n`r if (missing_table_flag==1) '### missing data percentages' `\n```{r, echo = FALSE,  fig.align='left', fig.width=10, comment=NULL}\n\n###############################\n# table 3: missing data table #\n###############################\n\nif (missing_table_flag==1) {missing_dt}\n\n```\n\n<br>\n\n`r if (students_per_test_flag==1) '### ID issues (by test)' `\n```{r, echo = FALSE,  fig.align='center', fig.width=10, comment=NULL}\n\n################################\n# table 4: ID issues (by test) #\n################################\n\nif (students_per_test_flag==1) {students_per_test_dt}\n\n```\n\n<br>\n\n`r if (students_per_grade_flag==1) '### students per grade (by test)' `\n```{r, echo = FALSE,  fig.align='center', fig.width=10, comment=NULL}\n\n#########################################\n# table 5: students per grade (by test) #\n#########################################\n\nif (students_per_grade_flag==1) {students_per_grade_dt}\n\n```\n\n<br>\n\n`r if (within_grade_flag==1) '### students per year (by test) ' `\n```{r, echo = FALSE,  fig.align='center', fig.width=10, comment=NULL}\n\n########################################\n# table 6: students per year (by test) #\n########################################\n\nif (within_grade_flag==1) {within_grade_dt}\n\n```\n\n<br>\n\n`r if (ss_model_stats_flag==1) '### scale score table' `\n```{r, echo = FALSE,  fig.align='center', fig.width=10, comment=NULL}\n\n##############################\n# table 7: scale score table # \n##############################\n\nif (ss_model_stats_flag==1) {ss_model_stats_dt}\n\n```\n\n\n<br>\n<br>\n\n## Unflagged Checks\n*Below are all the the qc_checks that were not flagged for possible problems*\n\n\n\n`r if (general_table_flag==0) '### general table' `\n```{r, echo = FALSE,  fig.align='center', fig.width=10, comment=NULL}\n\n##########################\n# table 1: general table #\n##########################\n\nif (general_table_flag==0){  general_table_dt}\n\n```\n\n<br>\n\n`r if (missing_vars_flag==0) '### missing variables' `\n```{r, echo = FALSE,  fig.align='center', fig.width=10, comment=NULL}\n\n##############################\n# table 2: missing variables #\n##############################\n\nif (missing_vars_flag==0) {miss_var_dt}\n\n```\n\n<br>\n\n`r if (missing_table_flag==0) '### missing data percentages' `\n```{r, echo = FALSE,  fig.align='left', fig.width=10, comment=NULL}\n\n###############################\n# table 3: missing data table #\n###############################\n\nif (missing_table_flag==0) {missing_dt}\n\n```\n\n<br>\n\n`r if (students_per_test_flag==0) '### ID issues (by test)' `\n```{r, echo = FALSE,  fig.align='center', fig.width=10, comment=NULL}\n\n################################\n# table 4: ID issues (by test) #\n################################\n\nif (students_per_test_flag==0) {students_per_test_dt}\n\n```\n\n<br>\n\n`r if (students_per_grade_flag==0) '### students per grade (by test) ' `\n```{r, echo = FALSE,  fig.align='center', fig.width=10, comment=NULL}\n\n#########################################\n# table 5: students per grade (by test) #\n#########################################\n\nif (students_per_grade_flag==0) {students_per_grade_dt}\n\n```\n\n<br>\n\n`r if (within_grade_flag==0) '### students per year (by test) ' `\n```{r, echo = FALSE,  fig.align='center', fig.width=10, comment=NULL}\n\n########################################\n# table 6: students per year (by test) #\n########################################\n\nif (within_grade_flag==0) {within_grade_dt}\n\n```\n\n<br>\n\n`r if (ss_model_stats_flag==0) '### scale score table' `\n```{r, echo = FALSE,  fig.align='center', fig.width=10, comment=NULL}\n\n##############################\n# table 7: scale score table # \n##############################\n\nif (ss_model_stats_flag==0) {ss_model_stats_dt}\n\n```\n\n\n\n## Histograms\n```{r, echo = FALSE,  warning = FALSE, message = FALSE, fig.align='center', fig.width=10, comment=NULL}\n\n# only print graphs if option is turned on\nif (params$opt_graphs==1) {print(test_hist_list)}\nif (params$opt_graphs==0) {message(\"The option to print histograms with scale score and test sem distributions has been turned off\")}\n\n\n```\n\n\n\n",
    "created" : 1456871140357.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "984233762",
    "id" : "7390D4F1",
    "lastKnownWriteTime" : 1456869048,
    "last_content_update" : 1456869048,
    "path" : "~/GitHub/eatestpackage/inst/rmd/qc_test_markdown.Rmd",
    "project_path" : "inst/rmd/qc_test_markdown.Rmd",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}